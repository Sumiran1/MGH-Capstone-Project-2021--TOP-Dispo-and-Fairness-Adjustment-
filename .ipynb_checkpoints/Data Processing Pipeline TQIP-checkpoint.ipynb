{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE IMPUTATION PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (38,40,42,44,46,48,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,94,97,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,154,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,347,348,349,350,351,352,353,354,413,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1215,1216,1217,1218,1227,1228,1229,1272,1274,1276,1278,1280,1282,1284,1286,1288) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_key</th>\n",
       "      <th>yobirth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race1</th>\n",
       "      <th>race2</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>teachsta</th>\n",
       "      <th>acslevel</th>\n",
       "      <th>acspedl</th>\n",
       "      <th>...</th>\n",
       "      <th>compldes8</th>\n",
       "      <th>complkey9</th>\n",
       "      <th>compldes9</th>\n",
       "      <th>complkey10</th>\n",
       "      <th>compldes10</th>\n",
       "      <th>complkey11</th>\n",
       "      <th>compldes11</th>\n",
       "      <th>complkey12</th>\n",
       "      <th>compldes12</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000ae7-4797</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Known/Not Recorded BIU 2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>University</td>\n",
       "      <td>I</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001376-9675</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Known/Not Recorded BIU 2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>University</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001774-08a9</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other Race</td>\n",
       "      <td>Not Known/Not Recorded BIU 2</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>University</td>\n",
       "      <td>I</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002cba-17d4</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Known/Not Recorded BIU 2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>University</td>\n",
       "      <td>I</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000048a2-1679</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Known/Not Recorded BIU 2</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>University</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         inc_key  yobirth   age  gender                      race1  \\\n",
       "0  00000ae7-4797   1985.0  28.0  Female                      White   \n",
       "1  00001376-9675   1960.0  54.0    Male                      White   \n",
       "2  00001774-08a9   1975.0  40.0    Male                 Other Race   \n",
       "3  00002cba-17d4   1996.0  16.0    Male  Black or African American   \n",
       "4  000048a2-1679   1993.0  20.0    Male                      White   \n",
       "\n",
       "                          race2                  ethnic    teachsta  \\\n",
       "0  Not Known/Not Recorded BIU 2  Not Hispanic or Latino  University   \n",
       "1  Not Known/Not Recorded BIU 2  Not Hispanic or Latino  University   \n",
       "2  Not Known/Not Recorded BIU 2      Hispanic or Latino  University   \n",
       "3  Not Known/Not Recorded BIU 2  Not Hispanic or Latino  University   \n",
       "4  Not Known/Not Recorded BIU 2  Not Hispanic or Latino  University   \n",
       "\n",
       "         acslevel         acspedl  ... compldes8 complkey9 compldes9  \\\n",
       "0               I  Not Applicable  ...       NaN       NaN       NaN   \n",
       "1               I               I  ...       NaN       NaN       NaN   \n",
       "2               I  Not Applicable  ...       NaN       NaN       NaN   \n",
       "3               I  Not Applicable  ...       NaN       NaN       NaN   \n",
       "4  Not Applicable  Not Applicable  ...       NaN       NaN       NaN   \n",
       "\n",
       "  complkey10 compldes10 complkey11 compldes11 complkey12 compldes12  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "        _merge  \n",
       "0  matched (3)  \n",
       "1  matched (3)  \n",
       "2  matched (3)  \n",
       "3  matched (3)  \n",
       "4  matched (3)  \n",
       "\n",
       "[5 rows x 1290 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mixtures of hamza's code and mine\n",
    "df_trauma = pd.read_csv(\"C:/Users/15125/Desktop/CAPSTONE PROJECT/RAW DATA/TQIP_2010_2016_Merged_MGHTrauma2019Jan.csv\")\n",
    "initial_length = len(df_trauma)\n",
    "df_trauma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General preprocessing\n",
    "allowed_eddisp = [\n",
    "  \"Operating Room\",\n",
    "  # \"Transferred to another hospital\",\n",
    "  \"Observation unit (unit that provides &lt; 24 hour stays)\",\n",
    "  \"Intensive Care Unit (ICU)\",\n",
    "  \"Telemetry/step-down unit (less acuity than ICU)\",\n",
    "  \"Floor bed (general admission, non specialty unit bed)\"\n",
    "  # \"Home without services\",\n",
    "  # \"Other (jail, institutional care facility, mental health, etc)\",\n",
    "  # \"Home with services\",\n",
    "  # \"Left against medical advice\",\n",
    "]\n",
    "df_trauma = df_trauma[df_trauma[\"eddisp\"].isin(allowed_eddisp)]\n",
    "df_trauma.loc[(df_trauma.tmode1.isnull()) & ~(df_trauma.tmode2.isnull()), \"tmode1\"] = df_trauma.loc[\n",
    "    (df_trauma.tmode1.isnull()) & ~(df_trauma.tmode2.isnull()), \"tmode2\"\n",
    "]\n",
    "\n",
    "comorkeys = [x for x in df_trauma.columns if \"comorkey\" in x]\n",
    "complkeys = [x for x in df_trauma.columns if \"complkey\" in x]\n",
    "predotkeys = [x for x in df_trauma.columns if \"predot\" in x]\n",
    "severitykeys = [x for x in df_trauma.columns if \"severity\" in x]\n",
    "\n",
    "## Daisy here refers to Daisy Zhou from Interpretable AI who assisted with the key selection\n",
    "columns_kept_daisy = (\n",
    "    comorkeys\n",
    "    + complkeys\n",
    "    + predotkeys\n",
    "    + severitykeys\n",
    "    + [\n",
    "        \"inc_key\", \"issais\", \"age\", \"gender\", \"race1\", \"ethnic\", \"acslevel\",\n",
    "        \"tmode1\", \"tmode2\", \"transfer\", \"alcohol\", \"drug1\", \"signsoflife\",\n",
    "        \"sbp1\", \"sbp2\", \"pulse1\", \"pulse2\", \"rr1\", \"rr2\",\n",
    "        \"oxysat1\", \"oxysat2\", \"temp1\", \"gcstot1\", \"gcstot2\",\n",
    "        \"ecode\", \"icd10_primary_ecode\", \"icd10_additonal_ecode\",\n",
    "        \"eddisp\", \"hospdisp\", \"yoadmit\", \"teachsta\", \"region\", \"hemorrhage_ctrl_type\",\n",
    "        \n",
    "    ]\n",
    ")\n",
    "df_trauma = df_trauma[columns_kept_daisy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Mapping values to NaNs #####\n",
    "for col_severity in severitykeys:\n",
    "    df_trauma[col_severity] = df_trauma[col_severity].replace({9: np.nan})\n",
    "df_trauma = df_trauma.replace({\n",
    "    \"Not Applicable BIU 1\": np.nan,\n",
    "    \"Not Known/Not Recorded BIU 2\": np.nan,\n",
    "    \"Not Applicable\": np.nan,\n",
    "    -99: np.nan,\n",
    "    -1: np.nan,\n",
    "    -2: np.nan,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comorbodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new column alcohol_use_disorder\n",
      "Created new column bleeding_disorder\n",
      "Created new column current_chemotherapy\n",
      "Created new column congestive_heart_failure\n",
      "Created new column current_smoker\n",
      "Created new column chronic_renal_failure\n",
      "Created new column history_cva\n",
      "Created new column diabetes\n",
      "Created new column disseminated_cancer\n",
      "Created new column copd\n",
      "Created new column steroid\n",
      "Created new column cirrhosis\n",
      "Created new column drug_use_disorder\n",
      "Created new column history_MI\n",
      "Created new column history_pvd\n",
      "Created new column hypertension_medication\n"
     ]
    }
   ],
   "source": [
    "for new_column, value in zip(\n",
    "    [\"alcohol_use_disorder\", \"bleeding_disorder\", \"current_chemotherapy\", \"congestive_heart_failure\",\n",
    "    \"current_smoker\", \"chronic_renal_failure\", \"history_cva\", \"diabetes\", \"disseminated_cancer\", \"copd\",\n",
    "    \"steroid\", \"cirrhosis\", \"drug_use_disorder\", \"history_MI\", \"history_pvd\", \"hypertension_medication\"],\n",
    "    [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 24, 25, 28, 17, 18, 19]\n",
    "):\n",
    "    df_trauma[new_column] = 0\n",
    "    df_trauma.loc[\n",
    "        ((df_trauma[\"comorkey1\"] == value) | (df_trauma[\"comorkey2\"] == value) |\n",
    "        (df_trauma[\"comorkey3\"] == value) | (df_trauma[\"comorkey4\"] == value) |\n",
    "        (df_trauma[\"comorkey5\"] == value) | (df_trauma[\"comorkey6\"] == value) |\n",
    "        (df_trauma[\"comorkey7\"] == value) | (df_trauma[\"comorkey8\"] == value) |\n",
    "        (df_trauma[\"comorkey9\"] == value) | (df_trauma[\"comorkey10\"] == value) |\n",
    "        (df_trauma[\"comorkey11\"] == value) | (df_trauma[\"comorkey12\"] == value)),\n",
    "        new_column\n",
    "    ] = 1\n",
    "    print(f\"Created new column {new_column}\")\n",
    "df_trauma = df_trauma.loc[:, [col for col in df_trauma.columns if \"comorkey\" not in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 means that the patient has no allowed morbidity, 1 means he has one\n",
    "df_trauma[\"morbidity\"] = 0\n",
    "morb_lists = []\n",
    "# allowed_morbidities = [4, 5, 8, 11, 12, 14, 15, 18, 19, 21, 22, 23, 25, 30, 31, 32, 35]\n",
    "# Modification of allowed morbidities on 15/12/2019: deleted 11, 15, 18, 22, 23, 30, 31,35\n",
    "allowed_morbidities = [4, 5, 8, 12, 14, 19, 21, 25, 32]\n",
    "for col_compl in complkeys:\n",
    "    df_trauma.loc[(df_trauma[col_compl].isin(allowed_morbidities)), \"morbidity\"] = 1\n",
    "    for morb in allowed_morbidities:\n",
    "        morb_list = np.zeros(len(df_trauma.index))\n",
    "        to_add_idx = df_trauma.loc[(df_trauma[col_compl].isin([morb])),:].index[df_trauma.loc[(df_trauma[col_compl].isin([morb])),:].index < len(df_trauma)]\n",
    "        morb_list[to_add_idx] = 1\n",
    "        morb_lists.append(morb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morb_names= ['Acute_Kidney_Injury','ARDS', 'Cardiac_Arrest_Requiring_CPR','Deep_Surgical_Site_Infection',\n",
    "            'Deep_Vein_Thrombosis', 'Organ_Space_Surgical_Site_Infection','Pulmonary_Embolism','Unplanned_Intubation',\n",
    "            'Severe_Sepsis']\n",
    "for name,vals in zip(morb_names, morb_lists):\n",
    "    df_trauma[name] = vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunt - Fall\n",
      "Blunt - Other\n",
      "Blunt - MVT occupant\n",
      "Blunt - MVT Pedal cyclist/pedestrian\n",
      "Blunt - MVT motorcyclist\n",
      "Penetrating - Gunshot Wound\n",
      "Penetrating - Stab Wound\n",
      "Penetrating - Other/Mixed\n",
      "===> Preprocessed the ICD mapping\n",
      "Blunt - Fall                            493077\n",
      "Unknown                                 246166\n",
      "Blunt - MVT occupant                    240367\n",
      "Blunt - Other                           147345\n",
      "Blunt - MVT motorcyclist                 76245\n",
      "Penetrating - Gunshot Wound              59054\n",
      "Blunt - MVT Pedal cyclist/pedestrian     52362\n",
      "Penetrating - Stab Wound                 31874\n",
      "Penetrating - Other/Mixed                   41\n",
      "Name: method_of_injury_ecode, dtype: int64\n",
      "Blunt - Fall\n",
      "Blunt - Other\n",
      "Blunt - MVT occupant\n",
      "Blunt - MVT Pedal cyclist/pedestrian\n",
      "Blunt - MVT motorcyclist\n",
      "Penetrating - Gunshot Wound\n",
      "Penetrating - Stab Wound\n",
      "Penetrating - Other/Mixed\n",
      "===> Preprocessed the ICD mapping primary icd\n",
      "Unknown                                 1077557\n",
      "Blunt - Fall                             133468\n",
      "Blunt - MVT occupant                      51719\n",
      "Blunt - Other                             34358\n",
      "Penetrating - Gunshot Wound               16873\n",
      "Blunt - MVT motorcyclist                  15930\n",
      "Blunt - MVT Pedal cyclist/pedestrian       9324\n",
      "Penetrating - Stab Wound                   7177\n",
      "Penetrating - Other/Mixed                   125\n",
      "Name: method_of_injury_icd_primary, dtype: int64\n",
      "Blunt - Fall                            605258\n",
      "Blunt - MVT occupant                    284365\n",
      "Blunt - Other                           176783\n",
      "Blunt - MVT motorcyclist                 90074\n",
      "Penetrating - Gunshot Wound              73562\n",
      "Blunt - MVT Pedal cyclist/pedestrian     60341\n",
      "Penetrating - Stab Wound                 38053\n",
      "Unknown                                  17929\n",
      "Penetrating - Other/Mixed                  166\n",
      "Name: method_of_injury, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping ecode (ecode2 has exactly the sames keys so it's useless to do any mapping)\n",
    "\n",
    "icd_mapping_ecode = pd.read_csv(\"C:/Users/15125/Desktop/CAPSTONE PROJECT/RAW DATA/icd.csv\", sep=\";\")\n",
    "dict_icd_mapping_ecode = {}\n",
    "for j in range(len(icd_mapping_ecode.columns)):\n",
    "    injury_type = icd_mapping_ecode.columns[j]\n",
    "    print(injury_type)\n",
    "    ecode_values = icd_mapping_ecode.iloc[0, j].split(' ')\n",
    "    ecode_values = [x[6:-1].split(\"\\n\")[0] if \"float\" in x else x.split(\"\\n\")[0] for x in ecode_values]\n",
    "    ecode_values = [float(x) if ')' not in x else float(x[:-1]) for x in ecode_values]\n",
    "    dict_icd_mapping_ecode.update({ecode: injury_type for ecode in ecode_values})\n",
    "print(\"===> Preprocessed the ICD mapping\")\n",
    "# We replace all the NaNs with \"Unknown\"\n",
    "df_trauma[\"method_of_injury_ecode\"] = df_trauma[\"ecode\"].astype(float).round(1).map(dict_icd_mapping_ecode)\n",
    "df_trauma[\"method_of_injury_ecode\"] = df_trauma[\"method_of_injury_ecode\"].replace({np.nan: \"Unknown\"})\n",
    "print(df_trauma[\"method_of_injury_ecode\"].value_counts())\n",
    "\n",
    "\n",
    "## Mapping icd10_primary_code\n",
    "# (icd10_additional_code has exactly the sames keys so it's useless to do any mapping)\n",
    "icd_mapping_primary = pd.read_csv(\"C:/Users/15125/Desktop/CAPSTONE PROJECT/RAW DATA/icd_primary_ecodes.csv\", sep=\";\")\n",
    "dict_icd_mapping_primary_icd = {}\n",
    "for j in range(len(icd_mapping_primary.columns)):\n",
    "    injury_type = icd_mapping_primary.columns[j]\n",
    "    print(injury_type)\n",
    "    primary_icd_values = icd_mapping_primary.iloc[0, j].split(' ')\n",
    "    primary_icd_values = [x.split(\"\\n\")[0] if \"\\n\" in x else x for x in primary_icd_values]\n",
    "    dict_icd_mapping_primary_icd.update({primary_icd: injury_type for primary_icd in primary_icd_values})\n",
    "print(\"===> Preprocessed the ICD mapping primary icd\")\n",
    "# We replace all the NaNs and unknowns (-1, -2) with \"Unknown\"\n",
    "dict_icd_mapping_primary_icd.update({-1: \"Unknown\", -2: \"Unknown\"})\n",
    "df_trauma[\"method_of_injury_icd_primary\"] = df_trauma[\"icd10_primary_ecode\"].map(\n",
    "    dict_icd_mapping_primary_icd\n",
    ")\n",
    "df_trauma[\"method_of_injury_icd_primary\"] = df_trauma[\"method_of_injury_icd_primary\"].replace({np.nan: \"Unknown\"})\n",
    "print(df_trauma[\"method_of_injury_icd_primary\"].value_counts())\n",
    "\n",
    "\n",
    "## Creating final method_of_injury from both other columns\n",
    "# This will be the final method_of_injury column built from the two intermediary columns\n",
    "df_trauma[\"method_of_injury\"] = df_trauma.method_of_injury_ecode\n",
    "# Completing ecode with primary_icd10_code\n",
    "df_trauma.loc[\n",
    "    (\n",
    "        (df_trauma.method_of_injury_ecode == \"Unknown\") &\n",
    "         (df_trauma.method_of_injury_icd_primary != \"Unknown\") &\n",
    "         (df_trauma.method_of_injury_ecode != df_trauma.method_of_injury_icd_primary)\n",
    "    )\n",
    "    , \"method_of_injury\"\n",
    "] = df_trauma.loc[\n",
    "    (\n",
    "        (df_trauma.method_of_injury_ecode == \"Unknown\") &\n",
    "         (df_trauma.method_of_injury_icd_primary != \"Unknown\") &\n",
    "         (df_trauma.method_of_injury_ecode != df_trauma.method_of_injury_icd_primary)\n",
    "    )\n",
    "    , \"method_of_injury_icd_primary\"\n",
    "]\n",
    "\n",
    "# Completing primary_icd10_code with ecode\n",
    "df_trauma.loc[\n",
    "    (\n",
    "        (df_trauma.method_of_injury_ecode != \"Unknown\") &\n",
    "        (df_trauma.method_of_injury_icd_primary == \"Unknown\") &\n",
    "        (df_trauma.method_of_injury_ecode != df_trauma.method_of_injury_icd_primary)\n",
    "    )\n",
    "    , \"method_of_injury\"\n",
    "] = df_trauma.loc[\n",
    "    (\n",
    "        (df_trauma.method_of_injury_ecode != \"Unknown\") &\n",
    "        (df_trauma.method_of_injury_icd_primary == \"Unknown\") &\n",
    "        (df_trauma.method_of_injury_ecode != df_trauma.method_of_injury_icd_primary)\n",
    "    )\n",
    "    , \"method_of_injury_ecode\"\n",
    "]\n",
    "# Dropping these two intermediary columns\n",
    "df_trauma.drop([\"method_of_injury_ecode\", \"method_of_injury_icd_primary\"], axis=1, inplace=True)\n",
    "print(df_trauma.method_of_injury.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trauma[\"alcohol\"] = df_trauma[\"alcohol\"].map({\n",
    "    \"Yes (confirmed by test [beyond legal limit])\": \"Alcohol\",\n",
    "    \"No (confirmed by test)\": \"Residual/no alcohol\",\n",
    "    \"Yes (confirmed by test [trace levels])\": \"Residual/no alcohol\",\n",
    "    \"No (not tested)\": np.nan\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severity of Trauma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face\n",
      "1.0    22.374903\n",
      "2.0     6.052961\n",
      "3.0     0.172814\n",
      "4.0     0.014185\n",
      "9.0     0.010323\n",
      "Name: Face_severity, dtype: float64\n",
      "% of NaNs:  71.37481424490042\n",
      "----------------------------------\n",
      "Neck\n",
      "1.0    0.770127\n",
      "3.0    0.552234\n",
      "2.0    0.246337\n",
      "4.0    0.036241\n",
      "9.0    0.007129\n",
      "5.0    0.006461\n",
      "6.0    0.000223\n",
      "Name: Neck_severity, dtype: float64\n",
      "% of NaNs:  98.38124781382679\n",
      "----------------------------------\n",
      "Head\n",
      "3.0    25.495811\n",
      "1.0     7.532170\n",
      "4.0     2.971859\n",
      "5.0     1.685368\n",
      "2.0     1.568104\n",
      "9.0     0.162566\n",
      "6.0     0.026958\n",
      "Name: Head_severity, dtype: float64\n",
      "% of NaNs:  60.557165041131626\n",
      "----------------------------------\n",
      "Thorax\n",
      "3.0    16.765674\n",
      "2.0     9.480658\n",
      "1.0     1.938314\n",
      "5.0     1.555553\n",
      "4.0     1.006958\n",
      "6.0     0.617216\n",
      "9.0     0.065650\n",
      "Name: Thorax_severity, dtype: float64\n",
      "% of NaNs:  68.5699772229529\n",
      "----------------------------------\n",
      "Abdomen\n",
      "2.0    6.153962\n",
      "1.0    4.664950\n",
      "4.0    2.721140\n",
      "3.0    2.653856\n",
      "5.0    0.615508\n",
      "9.0    0.037801\n",
      "6.0    0.003565\n",
      "Name: Abdomen_severity, dtype: float64\n",
      "% of NaNs:  83.14921825045246\n",
      "----------------------------------\n",
      "Spine\n",
      "2.0    17.112417\n",
      "3.0     2.658832\n",
      "4.0     1.327485\n",
      "1.0     0.785946\n",
      "5.0     0.589812\n",
      "6.0     0.131449\n",
      "9.0     0.042182\n",
      "Name: Spine_severity, dtype: float64\n",
      "% of NaNs:  77.35187678560686\n",
      "----------------------------------\n",
      "Upper_Extremity\n",
      "1.0    12.982248\n",
      "2.0     4.131951\n",
      "3.0     0.598724\n",
      "9.0     0.036835\n",
      "4.0     0.014556\n",
      "Name: Upper_Extremity_severity, dtype: float64\n",
      "% of NaNs:  82.23568562476467\n",
      "----------------------------------\n",
      "Lower_Extremity\n",
      "1.0    10.406222\n",
      "3.0    10.160108\n",
      "2.0     2.559837\n",
      "4.0     0.207348\n",
      "9.0     0.068101\n",
      "5.0     0.000817\n",
      "Name: Lower_Extremity_severity, dtype: float64\n",
      "% of NaNs:  76.59756812134292\n",
      "----------------------------------\n",
      "Pelvis_Perineum\n",
      "2.0    0.718067\n",
      "3.0    0.617735\n",
      "1.0    0.234454\n",
      "4.0    0.212843\n",
      "5.0    0.068472\n",
      "Name: Pelvis_Perineum_severity, dtype: float64\n",
      "% of NaNs:  98.14842732918886\n",
      "----------------------------------\n",
      "External\n",
      "1.0    7.481150\n",
      "2.0    0.043074\n",
      "3.0    0.001857\n",
      "5.0    0.001782\n",
      "4.0    0.000817\n",
      "6.0    0.000074\n",
      "Name: External_severity, dtype: float64\n",
      "% of NaNs:  92.47124648448495\n",
      "----------------------------------\n",
      "Length before transfer cleaning (keeping only 'No'): 1346531\n",
      "Length after transfer cleaning (keeping only 'No'): 959193\n",
      "Length before filtering NaNs from hospdisp: 959193\n",
      "Length after filtering NaNs from hospdisp: 958944\n"
     ]
    }
   ],
   "source": [
    "# # Predots Cleaning (severity)\n",
    "\n",
    "ais_inputs = pd.read_csv(\"C:/Users/15125/Desktop/CAPSTONE PROJECT/RAW DATA//ais_inputs.csv\", sep=\";\")\n",
    "columns_ais = list(ais_inputs.columns)[1:]\n",
    "injury_locations = [x[9:] for x in columns_ais]\n",
    "\n",
    "\n",
    "for col, location in zip(columns_ais, injury_locations):\n",
    "    vars()[f\"dict_ais_inputs_{location}\"] = {}\n",
    "    ais_temp = ais_inputs.loc[~ais_inputs[col].isnull(), [\"AIS_Predots\", col]]\n",
    "    predots = ais_temp.AIS_Predots.tolist()\n",
    "    severity = ais_temp[col].tolist()\n",
    "    vars()[f\"dict_ais_inputs_{location}\"].update({k:v for k,v in zip(predots, severity)})\n",
    "\n",
    "\n",
    "for location in injury_locations:\n",
    "    print(location)\n",
    "    df_temp = df_trauma.copy()\n",
    "    df_temp[f\"{location}_severity\"] = np.nan\n",
    "    for predot_col in predotkeys:\n",
    "        df_temp[predot_col] = df_temp[predot_col].astype(float)\n",
    "        df_temp[predot_col] = df_temp[predot_col].map(vars()[f\"dict_ais_inputs_{location}\"])\n",
    "    df_temp[f\"{location}_severity\"] = df_temp[predotkeys].max(axis=1)\n",
    "    df_trauma[f\"{location}_severity\"] = df_temp[f\"{location}_severity\"].copy()\n",
    "    print(df_trauma[f\"{location}_severity\"].value_counts()/len(df_trauma)*100)\n",
    "    print(\"% of NaNs: \",df_trauma[f\"{location}_severity\"].isnull().sum()/len(df_trauma)*100)\n",
    "    print('----------------------------------')\n",
    "\n",
    "# Taking the maximum severity for a patient over all new severity columns\n",
    "df_trauma[\"severity_max\"] = df_trauma[[f\"{location}_severity\" for location in injury_locations]].max(axis=1)\n",
    "\n",
    "\n",
    "# Transfers Cleaning\n",
    "\n",
    "print(f\"Length before transfer cleaning (keeping only 'No'): {len(df_trauma)}\")\n",
    "df_trauma = df_trauma[df_trauma.transfer == \"No\"]\n",
    "print(f\"Length after transfer cleaning (keeping only 'No'): {len(df_trauma)}\")\n",
    "\n",
    "\n",
    "# Filtering nan hospdisp\n",
    "print(f\"Length before filtering NaNs from hospdisp: {len(df_trauma)}\")\n",
    "df_trauma = df_trauma[~df_trauma.hospdisp.isnull()]\n",
    "print(f\"Length after filtering NaNs from hospdisp: {len(df_trauma)}\")\n",
    "\n",
    "\n",
    "# Dropping the severity 9 values (mean unknown)\n",
    "index_severity_9 = df_trauma[df_trauma.severity_max == 9].index.values\n",
    "df_trauma.drop(index_severity_9, inplace=True)\n",
    "\n",
    "# Dropping the severity 6 values\n",
    "index_severity_6 = df_trauma[df_trauma.severity_max == 6].index.values\n",
    "df_trauma.drop(index_severity_6, inplace=True)\n",
    "df_trauma.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Split Between Blunt and Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of blunt dataframe: 0.8927768765419581\n",
      "Length of penetrating dataframe: 0.09370986684240765\n"
     ]
    }
   ],
   "source": [
    "blunt_injury = ['Blunt - MVT occupant', 'Blunt - Fall', 'Blunt - MVT motorcyclist', 'Blunt - Other',\n",
    "               'Blunt - MVT Pedal cyclist/pedestrian']\n",
    "penetrating_injury = ['Penetrating - Gunshot Wound', 'Penetrating - Stab Wound', 'Penetrating - Other/Mixed']\n",
    "df_blunt = df_trauma[df_trauma.method_of_injury.isin(blunt_injury)].reset_index(drop=True)\n",
    "df_penetrating = df_trauma[df_trauma.method_of_injury.isin(penetrating_injury)].reset_index(drop=True)\n",
    "print(f\"Length of blunt dataframe: {len(df_blunt)/len(df_trauma)}\")\n",
    "print(f\"Length of penetrating dataframe: {len(df_penetrating)/len(df_trauma)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping for OptImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_columns_to_map = [\"gender\", \"race1\", \"acslevel\", \"signsoflife\",\n",
    "                      \"alcohol\", \"method_of_injury\", \"eddisp\",\"tmode1\",\"tmode2\",\"drug1\"]\n",
    "# Ordered:\n",
    "mapping_acslevel = {\"I\": 1, \"II\": 2, \"III\": 3, \"Unknown\": -1}\n",
    "#Non-ordered\n",
    "mapping_gender = {\"Female\": 1, \"Male\": 0}\n",
    "mapping_race1 = {'Other Race': 0, 'Black or African American': 1, 'White': 2, 'American Indian': 3,\n",
    "               'Native Hawaiian or Other Pacific Islander': 4, 'Asian': 5}\n",
    "mapping_signsoflife = {'Unknown':-1, 'Arrived with signs of life': 1, 'Arrived with NO signs of life': 0}\n",
    "mapping_alcohol = {\"Alcohol\": 1, \"Residual/no alcohol\": 0, \"Unknown\": -1}\n",
    "mapping_method_of_injury_penetrating = {'Penetrating - Stab Wound': 1, 'Penetrating - Gunshot Wound': 2,\n",
    "                                       'Penetrating - Other/Mixed':3}\n",
    "mapping_method_of_injury_blunt = {'Blunt - MVT occupant': 1, 'Blunt - Fall': 2, 'Blunt - MVT motorcyclist': 3,\n",
    " 'Blunt - Other': 4, 'Blunt - MVT Pedal cyclist/pedestrian': 5}\n",
    "mapping_eddisp = {'Operating Room' :0,\n",
    "       'Floor bed (general admission, non specialty unit bed)': 1,\n",
    "       'Telemetry/step-down unit (less acuity than ICU)': 2,\n",
    "       'Intensive Care Unit (ICU)': 3,\n",
    "       'Observation unit (unit that provides &lt; 24 hour stays)': 4}\n",
    "\n",
    "mapping_drug1 = {'No (not tested)': 0,\n",
    "       'Yes (confirmed by test [illegal use drug])': 1,\n",
    "       'No (confirmed by test)': 2,\n",
    "       'Yes (confirmed by test [prescription drug])': 3}\n",
    "\n",
    "mapping_tmode1 = {'Ground Ambulance': 0, 'Helicopter Ambulance' :1,\n",
    "       'Private/Public Vehicle/Walk-in': 2, 'Other': 3, 'Police': 4,\n",
    "       'Fixed-wing Ambulance': 5}\n",
    "\n",
    "mapping_tmode2 = mapping_tmode1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to keep, along with train-test split, and categorial variable imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blunt\n",
      "845324\n",
      "791160\n",
      "Size of test set with time separation for injury blunt: 167081\n",
      "--------------------------------------------------------\n",
      "penetrating\n",
      "88729\n",
      "79315\n",
      "Size of test set with time separation for injury penetrating: 17241\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# With the new morbidity and acslevel deleted on February 1 2020\n",
    "\n",
    "dict_injury = {0: \"blunt\", 1: \"penetrating\"}\n",
    "for i, df_injury in enumerate([df_blunt,df_penetrating]):\n",
    "    print(dict_injury[i])\n",
    "    columns_to_keep = [\n",
    "        \"inc_key\", \"age\", \"gender\", \"race1\",\n",
    "        # \"teachsta\", # \"region\",\n",
    "        \"acslevel\",  \"tmode1\", # \"transfer\",\n",
    "        \"signsoflife\", \"sbp1\",  \"sbp2\",\n",
    "        \"pulse1\",  \"pulse2\",\n",
    "        \"oxysat1\",  \"oxysat2\",\n",
    "        \"temp1\", \"gcstot1\",  \"gcstot2\",\n",
    "        \"alcohol\", \"bleeding_disorder\",\n",
    "        \"current_chemotherapy\", \"congestive_heart_failure\",\n",
    "        \"current_smoker\", \"chronic_renal_failure\",\n",
    "        \"history_cva\", \"diabetes\", \"disseminated_cancer\",\n",
    "        \"copd\", \"steroid\", \"cirrhosis\", \"history_MI\",\n",
    "        \"history_pvd\", \"hypertension_medication\",  \"eddisp\",\n",
    "        \"method_of_injury\",  # new AIS\"\n",
    "        \"Head_severity\", \"Face_severity\", \"Neck_severity\", \"Thorax_severity\",\n",
    "        \"Abdomen_severity\", \"Spine_severity\",\n",
    "        \"Upper_Extremity_severity\", \"Lower_Extremity_severity\",\n",
    "        \"Pelvis_Perineum_severity\", \"External_severity\", \"severity_max\",\"hospdisp\",\n",
    "        \"tmode1\", \"tmode2\",\"alcohol_use_disorder\", \"drug_use_disorder\", \"rr2\",\"rr1\",\n",
    "        \"issais\",\"morbidity\",\"drug1\",\"acslevel\"\n",
    "        #\"hemorrhage_ctrl_type\",\"hospdisp\"\n",
    "    ]\n",
    "    \n",
    "    columns_to_keep = df_injury.columns\n",
    "        \n",
    "    map_hosdisp= {'Discharged/Transferred to another type of rehabilitation or long term': 'post_acute_care',\n",
    "             'Discharged/Transferred to Skilled Nursing Facility': 'post_acute_care',\n",
    "             'Discharged/Transferred to an Intermediate Care Facility (ICF)': 'post_acute_care',\n",
    "             'Discharged/Transferred to a short-term general hospital for inpatient': 'post_acute_care',\n",
    "             'Discharged/Transferred to another type of institution not defined else': 'post_acute_care',\n",
    "             'Discharged/Transferred to inpatient rehab or designated unit': 'post_acute_care',\n",
    "             'Discharged/Transferred to Long Term Care hospital': 'post_acute_care',\n",
    "             'Discharged home with no home services': 'home',\n",
    "             'Discharge/Transferred to home under care of organized home health serv': 'home',\n",
    "             'Discharged to home or self-care (routine discharge)': 'home',\n",
    "             'Discharged/Transferred to court/law enforcement': 'home',\n",
    "             'Expired': 'died',\n",
    "             'Deceased/Expired': 'died',\n",
    "             'Left against medical advice or discontinued care': 'exclude',\n",
    "             'Discharged/Transferred to hospice care': 'exclude'\n",
    "             }\n",
    "\n",
    "\n",
    "    df_injury= df_injury.replace(map_hosdisp)\n",
    "\n",
    "#     len_pre_drop= len(df_injury)\n",
    "#     print(f'Number of rows pre drop: {len_pre_drop}')\n",
    "\n",
    "#     df_injury = df_injury[df_injury.hospdisp != 'Left against medical advice or discontinued care']\n",
    "#     df_injury = df_injury[df_injury.hospdisp != 'Discharged/Transferred to hospice care']\n",
    "\n",
    "\n",
    "#     len_post_drop= len(df_injury)\n",
    "#     print(f'Number of rows post drop: {len_post_drop}')\n",
    "    \n",
    "    hospdisp_target= df_injury.hospdisp\n",
    "\n",
    "    \n",
    "\n",
    "    # Getting indices of the two time periods for train/test split\n",
    "    index_before_2016 = df_injury[\n",
    "        df_injury.yoadmit < 2016\n",
    "        ].index.values\n",
    "    index_from_2016 = df_injury[\n",
    "        df_injury.yoadmit >= 2016\n",
    "        ].index.values\n",
    "\n",
    "    # Imputing categorical variables missing values with other categories\n",
    "    severities = [\n",
    "        \"Head_severity\",\n",
    "        \"Face_severity\",\n",
    "        \"Neck_severity\",\n",
    "        \"Thorax_severity\",\n",
    "        \"Abdomen_severity\",\n",
    "        \"Spine_severity\",\n",
    "        \"Upper_Extremity_severity\",\n",
    "        \"Lower_Extremity_severity\",\n",
    "        \"Pelvis_Perineum_severity\",\n",
    "        \"External_severity\",\n",
    "        \"severity_max\"\n",
    "    ]\n",
    "    for col in severities:\n",
    "        df_injury[col] = df_injury[col].fillna(0).astype(int)\n",
    "    #df_injury[\"acslevel\"] = df_injury[\"acslevel\"].fillna(\"Unknown\")\n",
    "    df_injury[\"race1\"] = df_injury[\"race1\"].fillna(\"Other Race\")\n",
    "    # Not filling signsoflife because will be optimputed\n",
    "    # df_injury[\"signsoflife\"] = df_injury[\"signsoflife\"].fillna(\"Unknown\")\n",
    "    df_injury[\"alcohol\"] = df_injury[\"alcohol\"].fillna(\"Unknown\")\n",
    "\n",
    "    for col in str_columns_to_map:\n",
    "        if col == \"method_of_injury\":\n",
    "#             print(col)\n",
    "#             print(df_injury[col].isnull().sum())\n",
    "            df_injury[col] = df_injury[col].replace(vars()[f\"mapping_{col}_{dict_injury[i]}\"]).astype(int)\n",
    "        else:\n",
    "#             print(col)\n",
    "#             print(df_injury[col].isnull().sum())\n",
    "            df_injury[col] = df_injury[col].replace(vars()[f\"mapping_{col}\"])\n",
    "            try:\n",
    "                df_injury[col] = df_injury[col].astype(int)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "     # X data train/test split\n",
    "    df_injury_train = df_injury.iloc[\n",
    "                      index_before_2016, :\n",
    "                      ].reset_index(drop=True)\n",
    "    df_injury_test = df_injury.iloc[\n",
    "                     index_from_2016, :\n",
    "                     ].reset_index(drop=True)\n",
    "    \n",
    "    df_injury_train = df_injury_train[columns_to_keep]\n",
    "    df_injury_test = df_injury_test[columns_to_keep]\n",
    "    \n",
    "    df_injury_train = df_injury_train[df_injury_train.hospdisp != 'exclude']\n",
    "    df_injury_test = df_injury_test[df_injury_test.hospdisp != 'exclude']\n",
    "    df_injury_train = df_injury_train[df_injury_train.hospdisp != 'died']\n",
    "    df_injury_test = df_injury_test[df_injury_test.hospdisp != 'died']\n",
    "    \n",
    "    # Label train/test split\n",
    "    \n",
    "    hospdisp_target_train= pd.DataFrame(hospdisp_target[index_before_2016])\n",
    "    hospdisp_target_test= pd.DataFrame(hospdisp_target[index_from_2016])\n",
    "    \n",
    "    print(len(hospdisp_target_train) + len(hospdisp_target_test))\n",
    "    \n",
    "    hospdisp_target_train= hospdisp_target_train[hospdisp_target_train.hospdisp != 'exclude']\n",
    "    hospdisp_target_test= hospdisp_target_test[hospdisp_target_test.hospdisp != 'exclude']\n",
    "    hospdisp_target_train= hospdisp_target_train[hospdisp_target_train.hospdisp != 'died']\n",
    "    hospdisp_target_test= hospdisp_target_test[hospdisp_target_test.hospdisp != 'died']\n",
    "   \n",
    "    print(len(hospdisp_target_train) + len(hospdisp_target_test))\n",
    "    \n",
    "    base_path_pre_process= 'C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST PRE PROCESSING'\n",
    "    \n",
    "    df_injury_train.to_csv(\n",
    "        f\"{base_path_pre_process}/{dict_injury[i]}/X_train_pre_process_full_{dict_injury[i]}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    df_injury_test.to_csv(\n",
    "        f\"{base_path_pre_process}/{dict_injury[i]}/X_test_pre_process_full_{dict_injury[i]}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    hospdisp_target_train.to_csv(\n",
    "        f\"{base_path_pre_process}/{dict_injury[i]}/y_train_pre_process_full_{dict_injury[i]}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    hospdisp_target_test.to_csv(\n",
    "        f\"{base_path_pre_process}/{dict_injury[i]}/y_test_pre_process_full_{dict_injury[i]}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Size of test set with time separation for injury {dict_injury[i]}: {len(df_injury_test)}\")\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation is done in a Julia file and then post imputation processing will proceed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST IMPUTATION PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_time_train_test_split(\n",
    "    injury: str, train_X_time_injury_imputed: pd.DataFrame, test_X_time_injury_imputed: pd.DataFrame\n",
    "):\n",
    "    # Time train/test split (saving the inc_keys as well)\n",
    "    # Saving train set\n",
    "    base_filepath_timesplit = \"C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST IMPUTATION PROCESSING\"\n",
    "    inc_keys_train_X_time_injury_imputed = train_X_time_injury_imputed.inc_key\n",
    "    inc_keys_train_X_time_injury_imputed.to_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/inc_keys_train_X_{injury}_final\"\n",
    "    )\n",
    "    train_X_time_injury_imputed.drop(\"inc_key\", axis=1).to_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/train_X_{injury}_final.csv\"\n",
    "    )\n",
    "\n",
    "    # Saving test set\n",
    "    inc_keys_test_X_time_injury_imputed = test_X_time_injury_imputed.inc_key\n",
    "    inc_keys_test_X_time_injury_imputed.to_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/inc_keys_test_X_{injury}_final\"\n",
    "    )\n",
    "    test_X_time_injury_imputed.drop(\"inc_key\", axis=1).to_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/test_X_{injury}_final.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_random_train_test_split(\n",
    "    injury: str,\n",
    "    train_X_time_injury_imputed: pd.DataFrame,\n",
    "    test_X_time_injury_imputed: pd.DataFrame,\n",
    "):\n",
    "    base_filepath_timesplit = 'C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST PRE PROCESSING'\n",
    "    y_train_hospdisp = pd.read_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/y_train_pre_process_{injury}.csv\",\n",
    "        header=None,\n",
    "    )\n",
    "    y_test_hospdisp = pd.read_csv(\n",
    "        f\"{base_filepath_timesplit}/{injury}/y_test_pre_process_{injury}.csv\",\n",
    "        header=None,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    X = pd.concat(\n",
    "        [train_X_time_injury_imputed, test_X_time_injury_imputed]\n",
    "    ).reset_index(drop=True)\n",
    "    y = pd.concat(\n",
    "        [y_train_hospdisp, y_test_hospdisp]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    ## need to do this so the split works\n",
    "    y= y.rename(columns={0: 'hospdisp'})\n",
    "    y= y[y.hospdisp != 'hospdisp']\n",
    "    \n",
    "    # Filter out severity 6\n",
    "    X[\"severity_max\"] = X[\n",
    "        [\n",
    "            \"Head_severity\",\n",
    "            \"Face_severity\",\n",
    "            \"Neck_severity\",\n",
    "            \"Thorax_severity\",\n",
    "            \"Abdomen_severity\",\n",
    "            \"Spine_severity\",\n",
    "            \"Upper_Extremity_severity\",\n",
    "            \"Lower_Extremity_severity\",\n",
    "            \"Pelvis_Perineum_severity\",\n",
    "            \"External_severity\",\n",
    "        ]\n",
    "    ].max(axis=1)\n",
    "    indices_severity_6_to_drop = X[X.severity_max == 6].index.values\n",
    "    X.drop(indices_severity_6_to_drop, axis=0, inplace=True)\n",
    "    y.drop(indices_severity_6_to_drop, axis=0, inplace=True)\n",
    "    X.drop(\"severity_max\", axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "    # Reset index\n",
    "    X.reset_index(inplace=True, drop=True)\n",
    "    y.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    ### to fix some earlier replacement that did not occur\n",
    "    replace_dict_2= {\n",
    "        \"Discharged/Transferred to Long Term Care Hospital\": \"post_acute_care\",\n",
    "        \"Discharged/transferred to a psychiatric hospital or psychiatric distin\": \"post_acute_care\"\n",
    "    }\n",
    "    \n",
    "    replace_dict_3= {\n",
    "        'home': 0,\n",
    "        'post_acute_care': 1\n",
    "    }\n",
    "    \n",
    "    y= y.replace(replace_dict_2)\n",
    "    y= y.replace(replace_dict_3)\n",
    "    \n",
    "    \n",
    "#### for smote addition refer to colab notebooks\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X, y, stratify=y, random_state=7, train_size=0.8\n",
    "    )\n",
    "\n",
    "#### Oversampling stuff\n",
    "#     X= pd.concat([train_X, train_y], axis=1)\n",
    "#     home = X[X.hospdisp==0]\n",
    "#     post_acute_care = X[X.hospdisp==1]\n",
    "#     post_acute_care_upsampled = resample(post_acute_care,\n",
    "#                           replace=True, # sample with replacement\n",
    "#                           n_samples=len(home)/2, # match number in majority class\n",
    "#                           random_state=1)\n",
    "    \n",
    "# #### Undersampling stuff\n",
    "#     home_downsampled = resample(home,\n",
    "#                           replace=True, # sample with replacement\n",
    "#                           n_samples=len(post_acute_care), # match number in majority class\n",
    "#                           random_state=1)\n",
    "    \n",
    "#     # combine majority and upsampled minority\n",
    "#     upsampled = pd.concat([home, post_acute_care_upsampled])\n",
    "#     train_y_os= pd.DataFrame(upsampled['hospdisp'])\n",
    "#     train_X_os = upsampled.drop('hospdisp', axis=1)\n",
    "    \n",
    "#     # combine downsampled majority and minority\n",
    "#     downsampled = pd.concat([home_downsampled, post_acute_care])\n",
    "#     train_y_ds= pd.DataFrame(downsampled['hospdisp'])\n",
    "#     train_X_ds = downsampled.drop('hospdisp', axis=1)\n",
    " \n",
    "    train_y.columns = [\"label\"]\n",
    "    test_y.columns = [\"label\"]\n",
    "    \n",
    "#     train_y_os.columns = [\"label\"]\n",
    "#     print(train_y_os.label.unique())\n",
    "    \n",
    "#     train_y_ds.columns = [\"label\"]\n",
    "#     print(train_y_ds.label.unique())\n",
    "    \n",
    "\n",
    "#     train_y_sm.columns = [\"label\"]\n",
    "#     print(train_y.label.unique())\n",
    "    \n",
    "#     test_y_sm.columns = [\"label\"]\n",
    "#     print(test_y_sm.label.unique())''\n",
    "    \n",
    "\n",
    "    base_path_final= 'C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST IMPUTATION PROCESSING'\n",
    "    \n",
    "#     train_X['inc_key'].to_csv(\n",
    "#         f\"{base_path_final}/{injury}/inc_keys_train_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     test_X['inc_key'].to_csv(\n",
    "#         f\"{base_path_final}/{injury}/inc_keys_test_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "#     train_X= train_X.drop(['inc_key'], axis=1)\n",
    "#     test_X= test_X.drop(['inc_key'], axis=1)\n",
    "#     train_X_sm= train_X_sm.drop(['inc_key'], axis=1)\n",
    "#     test_X_sm= test_X_sm.drop(['inc_key'], axis=1)\n",
    "\n",
    "    train_X['gcstot2'] = train_X['gcstot2'].round(0).astype(int)\n",
    "    test_X['gcstot2'] =  test_X['gcstot2'].round(0).astype(int)\n",
    "    train_X['gcstot1'] = train_X['gcstot1'].round(0).astype(int)\n",
    "    test_X['gcstot1'] =  test_X['gcstot1'].round(0).astype(int)\n",
    "    \n",
    "    train_X.to_csv(\n",
    "        f\"{base_path_final}/{injury}/X_train_{injury}_morb_splits.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    test_X.to_csv(\n",
    "        f\"{base_path_final}/{injury}/X_test_{injury}_morb_splits.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    train_y.to_csv(\n",
    "        f\"{base_path_final}/{injury}/y_train_{injury}_morb_splits.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    test_y.to_csv(\n",
    "        f\"{base_path_final}/{injury}/y_test_{injury}_morb_splits.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "#     train_X_os.to_csv(\n",
    "#         f\"{base_path_final}/{injury}/X_train_os_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     train_y_os.to_csv(\n",
    "#         f\"{base_path_final}/{injury}/y_train_os_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "#     train_X_ds.to_csv(\n",
    "#         f\"{base_path_final}/{injury}/X_train_ds_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     train_y_ds.to_csv(\n",
    "#         f\"{base_path_final}/{injury}/y_train_ds_random_final_{injury}.csv\",\n",
    "#         index=False\n",
    "\n",
    "#     # Saving the inc_keys and deleting column for X dataframes\n",
    "#     data_path_random = f\"/C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST IMPUTATION PROCESSING/{injury}/\"\n",
    "#     for filename in [\"train_X\", \"test_X\"]:\n",
    "#         inc_keys_filename = vars()[filename].inc_key.reset_index()\n",
    "#         inc_keys_filename.to_csv(\n",
    "#             data_path_random + f\"inc_keys_{filename}_{injury}_final_random.csv\", header=True\n",
    "#         )\n",
    "#         vars()[filename].drop(\"inc_key\", axis=1, inplace=True)\n",
    "\n",
    "#     ## Saving file\n",
    "#     for filename in [\n",
    "#         f\"train_X_{injury}_final_random\",\n",
    "#         f\"test_X_{injury}_final_random\",\n",
    "#     ]:\n",
    "#         vars()[filename].reset_index(drop=True, inplace=True)\n",
    "#         vars()[filename].to_csv(\n",
    "#             data_path_random + f\"{filename}.csv\", header=True\n",
    "#         )\n",
    "#         print(f\"Saved file {filename}\")\n",
    "\n",
    "      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Processing imputed data\n",
    "def preprocessing_imputed_data(injury: str):\n",
    "    # These columns will be remapped the other way around when OptImpute has been performed\n",
    "#     str_columns_to_map = [\n",
    "#         \"gender\",\n",
    "#         \"race1\",\n",
    "#         #\"acslevel\",\n",
    "#         \"signsoflife\",\n",
    "#         # \"alcohol\",\n",
    "#         \"method_of_injury\",\n",
    "#         \"eddisp\"\n",
    "#     ]\n",
    "    str_columns_to_map = [\"gender\", \"race1\", \"signsoflife\",\n",
    "                       \"eddisp\",\"tmode1\",\"tmode2\",\"drug1\"]\n",
    "    # Ordered:\n",
    "    #mapping_acslevel = {\"I\": 1, \"II\": 2, \"III\": 3, \"Unknown\": -1}\n",
    "    #mapping_acslevel_other_way = {v: k for k, v in mapping_acslevel.items()}\n",
    "\n",
    "    # Non-ordered\n",
    "    mapping_gender = {\"Female\": 1, \"Male\": 0}\n",
    "    mapping_gender_other_way = {v: k for k, v in mapping_gender.items()}\n",
    "\n",
    "    mapping_race1 = {\n",
    "        \"Other Race\": 0,\n",
    "        \"Black or African American\": 1,\n",
    "        \"White\": 2,\n",
    "        \"American Indian\": 3,\n",
    "        \"Native Hawaiian or Other Pacific Islander\": 4,\n",
    "        \"Asian\": 5,\n",
    "    }\n",
    "    mapping_race1_other_way = {v: k for k, v in mapping_race1.items()}\n",
    "\n",
    "    mapping_signsoflife = {\n",
    "        \"Unknown\": -1,\n",
    "        \"Arrived with signs of life\": 1,\n",
    "        \"Arrived with NO signs of life\": 0,\n",
    "    }\n",
    "    mapping_signsoflife_other_way = {v: k for k, v in mapping_signsoflife.items()}\n",
    "\n",
    "    # mapping_alcohol = {\"Alcohol\": 1, \"Residual/no alcohol\": 0, \"Unknown\": -1}\n",
    "    # mapping_alcohol_other_way = {v: k for k, v in mapping_alcohol.items()}\n",
    "\n",
    "    mapping_method_of_injury_penetrating = {\n",
    "        \"Penetrating - Stab Wound\": 1,\n",
    "        \"Penetrating - Gunshot Wound\": 2,\n",
    "        \"Penetrating - Other/Mixed\": 3,\n",
    "    }\n",
    "    mapping_method_of_injury_penetrating_other_way = {\n",
    "        v: k for k, v in mapping_method_of_injury_penetrating.items()\n",
    "    }\n",
    "\n",
    "    mapping_method_of_injury_blunt = {\n",
    "        \"Blunt - MVT occupant\": 1,\n",
    "        \"Blunt - Fall\": 2,\n",
    "        \"Blunt - MVT motorcyclist\": 3,\n",
    "        \"Blunt - Other\": 4,\n",
    "        \"Blunt - MVT Pedal cyclist/pedestrian\": 5,\n",
    "    }\n",
    "    mapping_method_of_injury_blunt_other_way = {\n",
    "        v: k for k, v in mapping_method_of_injury_blunt.items()\n",
    "    }\n",
    "    \n",
    "        \n",
    "    mapping_eddisp = {'Operating Room' :0,\n",
    "       'Floor bed (general admission, non specialty unit bed)': 1,\n",
    "       'Telemetry/step-down unit (less acuity than ICU)': 2,\n",
    "       'Intensive Care Unit (ICU)': 3,\n",
    "       'Observation unit (unit that provides &lt; 24 hour stays)': 4}\n",
    "    \n",
    "    mapping_eddisp_other_way = {\n",
    "        v: k for k, v in mapping_eddisp.items()\n",
    "    }\n",
    "    \n",
    "    mapping_drug1 = {'No (not tested)': 0,\n",
    "       'Yes (confirmed by test [illegal use drug])': 1,\n",
    "       'No (confirmed by test)': 2,\n",
    "       'Yes (confirmed by test [prescription drug])': 3}\n",
    "\n",
    "    mapping_tmode1 = {'Ground Ambulance': 0, 'Helicopter Ambulance' :1,\n",
    "           'Private/Public Vehicle/Walk-in': 2, 'Other': 3, 'Police': 4,\n",
    "           'Fixed-wing Ambulance': 5}\n",
    "\n",
    "    mapping_tmode2 = mapping_tmode1\n",
    "    \n",
    "    mapping_drug1_other_way = {\n",
    "        v: k for k, v in mapping_drug1.items()\n",
    "    }\n",
    "    \n",
    "    mapping_tmode1_other_way = {\n",
    "        v: k for k, v in mapping_tmode1.items()\n",
    "    }\n",
    "    \n",
    "    mapping_tmode2_other_way = {\n",
    "        v: k for k, v in mapping_tmode2.items()\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    test_X_time_injury_imputed = pd.read_csv(\n",
    "        f\"C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST IMPUTATION/{injury}/{injury}_imputed_test.csv\"\n",
    "    )\n",
    "    train_X_time_injury_imputed = pd.read_csv(\n",
    "        f\"C:/Users/15125/Desktop/CAPSTONE PROJECT/CLEANED DATA/POST IMPUTATION/{injury}/{injury}_imputed_train.csv\"\n",
    "    )\n",
    "    \n",
    "    # Replacing systolic blood pressure of less than 60 by -1 (<=> unknown or error)\n",
    "    train_X_time_injury_imputed.loc[train_X_time_injury_imputed.sbp1 < 60, \"sbp1\"] = -1\n",
    "    test_X_time_injury_imputed.loc[test_X_time_injury_imputed.sbp1 < 60, \"sbp1\"] = -1\n",
    "    \n",
    "    train_X_time_injury_imputed.reset_index(inplace=True, drop=True)\n",
    "    test_X_time_injury_imputed.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Dropped alcohol on 09/01/2020\n",
    "    new_columns = [\n",
    "        \"age\", \"gender\", \"race1\",\n",
    "        # \"teachsta\", # \"region\",\n",
    "        # \"transfer\",\n",
    "        \"signsoflife\",\"eddisp\", \"sbp1\",  \n",
    "        \"pulse1\",  \n",
    "        \"oxysat1\",  \n",
    "        \"temp1\", \"gcstot1\",  \n",
    "         \"bleeding_disorder\",\n",
    "        \"current_chemotherapy\", \"congestive_heart_failure\",\n",
    "        \"current_smoker\", \"chronic_renal_failure\",\n",
    "        \"history_cva\", \"diabetes\", \"disseminated_cancer\",\n",
    "        \"copd\", \"steroid\", \"cirrhosis\", \"history_MI\",\n",
    "        \"history_pvd\", \"hypertension_medication\",  \n",
    "        \"method_of_injury\",  # new AIS\"\n",
    "        \"Head_severity\", \"Face_severity\", \"Neck_severity\", \"Thorax_severity\",\n",
    "        \"Abdomen_severity\", \"Spine_severity\",\n",
    "        \"Upper_Extremity_severity\", \"Lower_Extremity_severity\",\n",
    "        \"Pelvis_Perineum_severity\", \"External_severity\", \"sbp2\", \"rr2\", \"drug_use_disorder\",\n",
    "        \"issais\",\"morbidity\", \"drug1\",  \"rr1\", \"pulse2\", \"acslevel\", \n",
    "        \"tmode1\", \"gcstot2\", \"oxysat2\",\"alcohol_use_disorder\", \"tmode2\", \"morbidity_splits\"\n",
    "        #\"hemorrhage_ctrl_type\",\"hospdisp\"\n",
    "    ]\n",
    "    \n",
    "    test_X_time_injury_imputed = test_X_time_injury_imputed.drop(columns= ['x1'])\n",
    "    train_X_time_injury_imputed = train_X_time_injury_imputed.drop(columns= ['x1'])\n",
    "    \n",
    "    test_X_time_injury_imputed.columns = new_columns\n",
    "    train_X_time_injury_imputed.columns = new_columns\n",
    "\n",
    "    for t_set in [\"train\", \"test\"]:\n",
    "        str_columns_to_map = [\"gender\", \"race1\", \"signsoflife\",\"eddisp\",\"tmode1\",\"tmode2\",\"drug1\"]# ,\"alcohol\", \"acslevel\"]\n",
    "        vars()[f\"{t_set}_X_time_injury_imputed\"][\"method_of_injury\"] = vars()[\n",
    "            f\"{t_set}_X_time_injury_imputed\"\n",
    "        ][\"method_of_injury\"].map(\n",
    "            vars()[f\"mapping_method_of_injury_{injury}_other_way\"]\n",
    "        )\n",
    "\n",
    "        # Map the other way around the categorical features that have been imputed\n",
    "        for col_map in str_columns_to_map:\n",
    "            vars()[f\"{t_set}_X_time_injury_imputed\"][col_map] = (\n",
    "                vars()[f\"{t_set}_X_time_injury_imputed\"][col_map].round(0).astype(int)\n",
    "            )\n",
    "            vars()[f\"{t_set}_X_time_injury_imputed\"][col_map] = vars()[\n",
    "                f\"{t_set}_X_time_injury_imputed\"\n",
    "            ][col_map].map(vars()[f\"mapping_{col_map}_other_way\"])\n",
    "        print(f\"Preprocessed {t_set} dataset for {injury} injuries\")\n",
    "\n",
    "#     save_time_train_test_split(injury, train_X_time_injury_imputed, test_X_time_injury_imputed)\n",
    "    save_random_train_test_split(\n",
    "        injury, train_X_time_injury_imputed, test_X_time_injury_imputed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed train dataset for penetrating injuries\n",
      "Preprocessed test dataset for penetrating injuries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed train dataset for blunt injuries\n",
      "Preprocessed test dataset for blunt injuries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\15125\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "preprocessing_imputed_data(\"penetrating\")\n",
    "preprocessing_imputed_data(\"blunt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
